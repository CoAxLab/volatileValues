{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    Simulation Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two-alternative drift diffusion model [DDM] relies on three fundamental assumptions: \n",
    "\n",
    "I. Evidence favoring each alternative is integrated over time.\n",
    "\n",
    "II. Decision process errors are normally distributed with a dispersion of $\\sigma^2$, [$\\epsilon \\textrm{~} N(0,\\sigma^2)$] \n",
    "\n",
    "III. A decision is made when sufficient evidence has accumulated for one alternative over the other.\n",
    "\n",
    "*(The physics of optimal decision making ~ Bogacz et al., 2006)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nomenclature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Bayesian belief model parameters**</center>\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu = \\textrm{mean reward difference between targets} && \\Omega = \\textrm{change point probability}\\\\\n",
    "\\hat{\\delta} = \\textrm{reward prediction error} && \\delta = \\textrm{dist. mean belief prediction error}\\\\\n",
    "\\sigma^2_n = \\textrm{variance of the generative distribution} && \\sigma^2_t = \\textrm{estimated variance}\\\\ \n",
    "\\phi = \\textrm{model confidence} && H = \\textrm{hazard rate}\\\\\n",
    "r_t = \\textrm{reward observed}\\\\ \n",
    "\\end{align}\n",
    "$$\n",
    "<br>\n",
    "<center>**DDM parameters** </center>\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta= \\textrm{execution state} && \\tau = \\textrm{time step}\\\\\n",
    "a = \\textrm{boundary} && V = \\textrm{execution drift rate}\\\\  \n",
    " && \\epsilon = \\textrm{error} \n",
    "\\end{align}\n",
    "$$\n",
    "<br>\n",
    "<center>**Adaptive parameters**</center>\n",
    "$$\n",
    "\\begin{align}\n",
    "a_{t+1} = \\textrm{boundary height learning rate}  && d\\theta = \\textrm{drift learning rate} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given trial, \n",
    "$$\\theta(\\tau)= \\theta(\\tau-\\Delta\\tau) + v\\Delta\\tau + \\epsilon(\\tau)$$\n",
    "where: \n",
    "$$\\theta = V_{t_1} - V_{t_2}$$\n",
    "\n",
    "An action is executed when the decision process for a given time step crossed the boundary [$a$]: \n",
    "$$\\textrm{response} = \\begin{cases} 1 \\;  \\textrm{if} \\; \\theta(\\tau) \\geq a \\\\\n",
    "\\textrm{else} \\; 0\\end{cases}\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian belief and learning rate estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Empirically derived learning rates**<br>\n",
    "Participant learning rates are estimated for each trial by calculating the ratio of observed reward displacement from one trial to the next to the prediction error. How much does each new outcome influence subsequent prediction?\n",
    "$$\\hat{\\alpha_t} = \\frac{r_{t+1} - r_t}{\\hat\\delta_t}$$\n",
    "\n",
    "The reward prediction error for the learning rate estimate for each participant is the difference between the highest reward on that trial [$r_max$] and the reward associated with the selected target [$r_t$]: \n",
    "$$\\hat{\\delta_t} = r_max - r_t$$\n",
    "\n",
    "**Model-based belief and learning rate estimation**<br>\n",
    "The learning rate of the model [$\\alpha$] is influenced by the change point probability, [$\\Omega$, the model's suspicion that the location of the mean has shifted] and the model confidence [$\\phi$, uncertainty arising from imprecise estimate of the mean]. The learning rate should be high if either 1) a change in the mean of the distribution of reward is likely [$\\Omega$ is high] or 2) the estimate of the mean is highly imprecise [$\\sigma^2_n$ is high].\n",
    "$$\\alpha_t = \\Omega_t + (1-\\Omega)(1-\\phi_t)$$\n",
    "\n",
    "The belief estimate of the mean of the distribution of rewards on the next trial: \n",
    "$$B_{t+1} = B_t + \\alpha_t\\delta_t$$\n",
    "\n",
    "The prediction error, $\\delta$, is the difference between the model belief and the current sample: \n",
    "$$\\delta_t = r_t - B_t$$\n",
    "\n",
    "If $\\alpha_t$ is 0, the current sample will not update the model belief estimate at all but if \n",
    "$\\alpha_t$ is 1, the current sample will entirely dictate the model's belief estimate. \n",
    "***\n",
    "<br>\n",
    "**Changepoint probability**<br>\n",
    "The changepoint probability is the likelihood that a new sample is drawn from the same Gaussian distribution centered about the current belief estimate of the model relative to the likelihood that a new sample is drawn from a uniform distribution. The changepoint probability will be close to 1 as the relative probability of a sample coming from a uniform distribution increases. H is the probability that the mean of the distribution has changed. \n",
    "\n",
    "$$\\Omega_t = \\frac{U(r_t)H}{U(r_t)H + N(r_t|B_t,\\sigma^2_t)(1-H)}$$\n",
    "\n",
    "**Estimated variance**<br>\n",
    "$$\\sigma^2_t = \\sigma^2_n + \\frac{(1-\\phi_t)\\sigma^2_n}{\\phi_t}$$\n",
    "\n",
    "\n",
    "**Model confidence**<br>\n",
    "The model confidence [$\\phi$] is a function of the changepoint probability [$\\Omega$] and the variance of the generative distribution [$\\sigma^2_n$]. The first term is the variance when a changepoint is assumed to have occurred. The second term is the variance conditional on no changepoint (slowly decaying uncertainty). The third term is the rise in uncertainty when the model is unsure whether a changepoint has occurred. The same terms are in the denominator with an added variance term to reflect uncertainty arising from noise. \n",
    "\n",
    "$$RU_t = \\frac{\\Omega_t\\sigma^2_n + (1-\\Omega_t)(1-\\phi_t)\\sigma^2_n + \\Omega_t(1-\\Omega_t)(\\delta_t\\phi_t)^2}{\\Omega_t\\sigma^2_n + (1-\\Omega_t)(1-\\phi_t)\\sigma^2_n + \\Omega_t(1-\\Omega_t)(\\delta_t\\phi_t)^2+\\sigma^2_n}$$\n",
    "<br>\n",
    "$$\\phi_{t+1} =  1 - RU$$\n",
    "\n",
    "_*note that the calculation of model confidence in the paper is actually reward uncertainty, so we take the additive inverse*_ <br>\n",
    "*Vaghi et al., 2017*\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate adaptive models \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are candidate models of the influence of reward, model confidence, and change point probability on the update of the decision boundary and the drift rate of the decision process. Our initial goal is to estimate the scalar $\\beta$ in each, noting which model most efficiently finds the optimal target. \n",
    "<br><br>\n",
    "I) The drift learning rate alone may vary as a function of the reward difference between targets and model confidence:\n",
    "$$d\\theta = \\hat\\beta(\\mu_t\\phi_t)dt + dW$$\n",
    "<br>\n",
    "II) The boundary alone may adapt as a function of the change point probability:\n",
    "$$a_{t+1} = a_0 + \\hat\\beta_\\Omega\\Omega_t$$\n",
    "<br>\n",
    "III) The drift learning rate may adapt as a function of the reward difference between targets and model confidence, and the boundary may adapt as a function of change point probability:\n",
    "$$d\\theta = \\hat\\beta(\\mu_t\\phi_t)dt + dW\\\\\n",
    "a_{t+1} = a_0 + \\hat\\beta_\\Omega\\Omega_t$$\n",
    "<br>\n",
    "IV) The drift learning rate may vary as a function of the reward difference between targets and the boundary may vary as a function of model confidence:\n",
    "$$d\\theta = \\hat\\beta_\\mu\\mu_tdt + dW\\\\\n",
    "a_{t+1} = a_0 - \\hat\\beta_\\phi\\phi_t$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost [to be updated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deviance of model predictions [$\\hat{\\mu}$] from the observed data [$\\mu$] is evaluated according to the following chi-square function of residuals weighted by variance, where $N$ corresponds to the total number of epochs: \n",
    "\n",
    "$$X^2 = \\sum_i^{N}W_{acc,\\:i}\\;(\\mu_{acc,i} - \\hat{\\mu}_{acc,i})^2 + \\sum_i^{N}W_{rt,\\:i}\\;(\\mu_{rt,i} - \\hat{\\mu}_{rt,i})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
